# Conformal Prediction

## No.:
## Title:
## https links: 


1.
Conformal prediction beyond exchangeability
https://arxiv.org/abs/2202.13415


Distribution-free prediction: exchangeability and beyond
https://imstat.org/2022/04/01/medallion-lecture-rina-foygel-barber/



2.
Conformalized Online Learning: Online Calibration Without a Holdout Set
https://stephenbates19.github.io/research.html


https://arxiv.org/abs/2205.09095
We develop a framework for constructing uncertainty sets with a valid coverage guarantee in an online setting, 
in which the underlying data distribution can drastically -- and even adversarially -- shift over time. 
The technique we propose is highly flexible as it can be integrated with any online learning algorithm, 
requiring minimal implementation effort and computational cost. 
A key advantage of our method over existing alternatives -- which also build on conformal inference -- is that 
we do not need to split the data into training and holdout calibration sets. 
This allows us to fit the predictive model in a fully online manner, utilizing the most recent observation 
for constructing calibrated uncertainty sets. 
Consequently, and in contrast with existing techniques, (i) the sets we build can quickly adapt to new changes in the distribution; 
and (ii) our procedure does not require refitting the model at each time step. 
Using synthetic and real-world benchmark data sets, we demonstrate the validity of our theory 
and the improved performance of our proposal over existing techniques. 
To demonstrate the greater flexibility of the proposed method, we show how to construct valid intervals 
for a multiple-output regression problem that 
previous sequential calibration methods cannot handle due to impractical computational and memory requirements.


Reliable Predictive Inference in Time-Series Settings
https://github.com/Shai128/rci

An important factor to guarantee a responsible use of data-driven systems is 
that we should be able to communicate their uncertainty to decision makers. 
This can be accomplished by constructing prediction sets, 
which provide an intuitive measure of the limits of predictive performance.

This package contains a Python implementation of Rolling Conformal Inference (Rolling CI) [1] methodology 
for constructing distribution-free prediction sets.



3.
Practical Adversarial Multivalid Conformal Prediction
https://arxiv.org/abs/2206.01067

https://arxiv.org/pdf/2206.01067

We give a simple, generic conformal prediction method for sequential prediction that 
achieves target empirical coverage guarantees against adversarially chosen data. 
It is computationally lightweight -- comparable to split conformal prediction -- but 
does not require having a held-out validation set, and so all data can be used for training models 
from which to derive a conformal score. 
It gives stronger than marginal coverage guarantees in two ways. 
First, it gives threshold calibrated prediction sets that 
have correct empirical coverage even conditional on the threshold 
used to form the prediction set from the conformal score. 
Second, the user can specify an arbitrary collection of subsets of 
the feature space -- possibly intersecting -- and the coverage guarantees 
also hold conditional on membership in each of these subsets. 
We call our algorithm MVP, short for MultiValid Prediction. 
We give both theory and an extensive set of empirical evaluations.



4.
Workshop on Distribution-Free Uncertainty Quantification
Anastasios Angelopoulos · Stephen Bates · Sharon Li · Aaditya Ramdas · Ryan Tibshirani

Visit https://sites.google.com/berkeley.edu/dfuq21/ for details!

https://icml.cc/Conferences/2021/ScheduleMultitrack?event=8373


5.
ADVERSARIALLY ROBUST CONFORMAL PREDICTION
Asaf Gendler , Tsui-Wei Weng , Luca Daniel , Yaniv Romano
https://openreview.net/pdf?id=9L1BsI4wP1H



6.
Adaptive Conformal Predictions for Time Series
Margaux Zaffran, Aymeric Dieuleveut, Olivier Féron, Yannig Goude, Julie Josse
https://hal.archives-ouvertes.fr/hal-03573934/file/AdaptiveConformalPredictionsTimeSeries.pdf



7.
International Seminar on Distribution-Free Statistics Talk “Conformal Training: Learning Optimal Conformal Classifiers”
https://davidstutz.de/international-seminar-on-distribution-free-statistics-talk-conformal-training-learning-optimal-conformal-classifiers/

https://davidstutz.de/wordpress/wp-content/uploads/2021/11/conformal-training-isdfs2021.pdf

Modern deep learning based classifiers show very high accuracy on test data 
but this does not provide sufficient guarantees for safe deployment, especially in high-stake AI applications such as medical diagnosis. 
Usually, predictions are obtained without a reliable uncertainty estimate or a formal guarantee. 
Conformal prediction (CP) addresses these issues by using the classifier's probability estimates to predict confidence sets 
containing the true class with a user-specified probability. 
However, using CP as a separate processing step after training 
prevents the underlying model from adapting to the prediction of confidence sets. 
Thus, this paper explores strategies to differentiate through CP during training 
with the goal of training model with the conformal wrapper end-to-end. 
In our approach, conformal training (ConfTr), we specifically "simulate" conformalization on mini-batches during training. 
We show that ConfTr outperforms state-of-the-art CP methods for classification 
by reducing the average confidence set size (inefficiency). 
Moreover, it allows to "shape" the confidence sets predicted at test time, which is difficult for standard CP. 
On experiments with several datasets, we show ConfTr can influence how inefficiency is distributed across classes, 
or guide the composition of confidence sets in terms of the included classes, while retaining the guarantees offered by CP.



